{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extracting all actor links from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://en.wikipedia.org/wiki/List_of_Indian_film_actors\", \"https://en.wikipedia.org/wiki/List_of_Indian_film_actresses\"] \n",
    "\n",
    "base = \"https://en.wikipedia.org\"\n",
    "actor_urls = []\n",
    "\n",
    "for i, url in enumerate(urls, 0):    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    divs = soup.find_all('div', class_=\"div-col columns column-width\")\n",
    "    for div in divs:\n",
    "        lis = div.findChildren(\"a\", recursive=\"False\")\n",
    "        for li in lis:\n",
    "            actor_urls.append((base+li['href'], i))\n",
    "            \n",
    "print(\"Total {} actors got.\".format(len(actor_urls)))\n",
    "display(actor_urls[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Download images from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://www.google.com/search?hl=en&site=imghp&tbm=isch&tbs=isz:l&q=\"\n",
    "\n",
    "def google_image(name, fn):\n",
    "    headers= {\"User.Agent\":\"Chrome/80.0.3987.122\"}\n",
    "    url = search_url+name\n",
    "    \n",
    "    req= requests.get(url,headers=headers)\n",
    "    html=req.content\n",
    "    \n",
    "    a = requests.get(url).text\n",
    "    result_url=\"\"\n",
    "    b=a.find(\"http://t1.gstatic.com\")\n",
    "    for i in range(b,b+1000):\n",
    "        if a[i]=='\"':\n",
    "            break\n",
    "        result_url+=a[i]\n",
    "    #print(result_url)\n",
    "    response = requests.get(result_url, stream=True)\n",
    "    \n",
    "    file = open(\"./Images/{}.jpg\".format(fn), 'wb')\n",
    "    \n",
    "    response.raw.decode_content = True\n",
    "    shutil.copyfileobj(response.raw, file)\n",
    "    del response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Download images from Wikipedia only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, fn):\n",
    "    response = requests.get(url, stream=True)\n",
    "    \n",
    "    file = open(\"./Images/{}.jpg\".format(fn), 'wb')\n",
    "    \n",
    "    response.raw.decode_content = True\n",
    "    shutil.copyfileobj(response.raw, file)\n",
    "    del response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get actor age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(query):\n",
    "    query += \" age\"\n",
    "    query = query.replace(' ', '+')\n",
    "    URL = f\"https://google.com/search?q={query}\"\n",
    "    \n",
    "    headers = {\"User.Agent\": \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"}\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    else:\n",
    "        # print(\"{} - not found\".format(URL))\n",
    "        return \"Unavailable\"\n",
    "    \n",
    "    div = soup.find(\"div\", class_=\"BNeawe\").find(\"div\", class_=\"BNeawe\")\n",
    "    if div:\n",
    "        if len(div.text) < 50:\n",
    "            return div.text\n",
    "        else:\n",
    "            return \"Unavailable\"\n",
    "    else:\n",
    "        return \"Unavailable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get actor heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_height(query):\n",
    "    query += \" height\"\n",
    "    query = query.replace(' ', '+')\n",
    "    URL = f\"https://google.com/search?q={query}\"\n",
    "    \n",
    "    headers = {\"User.Agent\": \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"}\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    else:\n",
    "        # print(\"{} - not found\".format(URL))\n",
    "        return \"Unavailable\"\n",
    "    \n",
    "    div = soup.find('div', class_=\"BNeawe iBp4i AP7Wnd\")\n",
    "    if div:\n",
    "        txt = div.text\n",
    "        if len(txt) < 10:\n",
    "            return txt\n",
    "        else:\n",
    "            return txt.split('.')[0]\n",
    "    else:\n",
    "        table = soup.find(\"table\", class_=\"LnMnt\")\n",
    "        if table:\n",
    "            trs = table.find_all('tr')\n",
    "            for tr in trs:\n",
    "                if tr.find_all('td')[0].text == 'HEIGHT':\n",
    "                    return tr.find_all('td')[1].text.split('-')[2][1:7]\n",
    "                    break\n",
    "        else:\n",
    "            div = soup.find('div', class_=\"BNeawe\").find('div', class_=\"BNeawe\")\n",
    "            if div:\n",
    "                txt = div.text\n",
    "                if len(txt) > 10:\n",
    "                    return txt.split(\".\")[0]\n",
    "                else:\n",
    "                    return div.text\n",
    "            else:\n",
    "                return \"Unavailable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check if actor is dead or alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alive(query):\n",
    "    query = \"is \"+ query + \" alive\"\n",
    "    query = query.replace(' ', '+')\n",
    "    URL = f\"https://google.com/search?q={query}\"\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"}\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    else:\n",
    "        # print(\"{} - not found\".format(URL))\n",
    "        return \"Unavailable\"\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    #print(soup.prettify())\n",
    "    d = soup.find(text=\"Deceased\")\n",
    "    c = soup.find(text=\"Cause of death\")\n",
    "    #print(d, c)\n",
    "    \n",
    "    if d or c:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "#is_alive(\"Mahesh Babu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get all information about each actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'name':[], 'image':[], 'gender':[], 'age':[], 'height':[], 'description':[]}\n",
    "\n",
    "for i, url in enumerate(actor_urls, 1):\n",
    "    #print(actor_url)\n",
    "    actor_url = url[0]\n",
    "    gender = url[1]\n",
    "    \n",
    "    source = requests.get(actor_url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    name = soup.find('h1', id=\"firstHeading\").text\n",
    "    \n",
    "    try:\n",
    "        paras = soup.find('div', class_=\"mw-parser-output\").find_all('p')\n",
    "        for para in paras:\n",
    "            txt = para.text\n",
    "            if len(txt) > 3: \n",
    "                txt = re.sub(r'\\[.*?\\]', '', txt)\n",
    "                txt = txt.strip()\n",
    "                data['description'].append(txt)\n",
    "                #print(\"\\r{}\".format(name), end=\"\\r\")\n",
    "                break\n",
    "    except AttributeError:\n",
    "        data['description'].append(\"NaN\")\n",
    "    \n",
    "    box = soup.find('table', class_=\"infobox\")\n",
    "    if box:\n",
    "        img = box.find(\"a\", class_=\"image\")\n",
    "        if img:\n",
    "            img = \"https:\"+img.find_all(\"img\")[0]['src']\n",
    "            download_image(img, i)\n",
    "        else:\n",
    "            google_image(name+' '+box.find('tr').text, i)\n",
    "    else:\n",
    "        google_image(name, i)\n",
    "        \n",
    "    age = get_age(name)\n",
    "    \n",
    "    height = get_height(name)\n",
    "    \n",
    "    data[\"name\"].append(name)\n",
    "    data[\"image\"].append(str(i)+'.jpg')\n",
    "    data[\"age\"].append(age)\n",
    "    data[\"height\"].append(height)\n",
    "    data[\"gender\"].append(\"Male\" if gender == 0 else \"Female\")\n",
    "    \n",
    "    print(\"{}/{} Actors downloaded. [{}, {}, {}]\".format(i, len(actor_urls), name, age, height))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('./data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check the data downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "display(df.head())\n",
    "print(\"Total actors got - {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of actors without each type of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = df['age'].value_counts()['Unavailable']\n",
    "heights = df['height'].value_counts()['Unavailable']\n",
    "des = df['description'].isnull().sum()\n",
    "\n",
    "print(\"Total actors: {}\\n\".format(df.shape[0]))\n",
    "print('Number of ages unavailable: {}.\\nNumber of heights unavailable: {}.\\nNumber of descriptions unavailable: {}'.format(ages, heights, des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for name in df['name']:\n",
    "    l.append(is_alive(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
